import { describe, test, expect } from "bun:test";
import { stringifyTypedJsonAsync } from "../../src/shared/TypedJsonUtils";

describe("Generator Streaming Performance", () => {
    
    test("Benchmark: Simple string chunks (no binary)", async () => {
        const iterations = 1000;
        const chunks: string[] = [];
        
        for (let i = 0; i < iterations; i++) {
            chunks.push(`Message ${i}`);
        }
        
        // Test stringifyTypedJsonAsync with simple strings
        const start = performance.now();
        for (const chunk of chunks) {
            await stringifyTypedJsonAsync(chunk);
        }
        const duration = performance.now() - start;
        
        console.log(`âœ… Serialized ${iterations} simple strings in ${duration.toFixed(2)}ms`);
        console.log(`   Average: ${(duration / iterations).toFixed(4)}ms per chunk`);
        console.log(`   Throughput: ${(iterations / (duration / 1000)).toFixed(0)} chunks/second`);
        
        expect(duration).toBeLessThan(500); // Should be fast
    });
    
    test("Benchmark: Simple objects (no binary)", async () => {
        const iterations = 1000;
        const chunks: object[] = [];
        
        for (let i = 0; i < iterations; i++) {
            chunks.push({ id: i, message: `Message ${i}`, timestamp: Date.now() });
        }
        
        // Test stringifyTypedJsonAsync with simple objects
        const start = performance.now();
        for (const chunk of chunks) {
            await stringifyTypedJsonAsync(chunk);
        }
        const duration = performance.now() - start;
        
        console.log(`âœ… Serialized ${iterations} simple objects in ${duration.toFixed(2)}ms`);
        console.log(`   Average: ${(duration / iterations).toFixed(4)}ms per chunk`);
        console.log(`   Throughput: ${(iterations / (duration / 1000)).toFixed(0)} chunks/second`);
        
        expect(duration).toBeLessThan(500);
    });
    
    test("Benchmark: Binary chunks (ArrayBuffer)", async () => {
        const iterations = 100; // Less iterations for binary
        const chunks: ArrayBuffer[] = [];
        
        for (let i = 0; i < iterations; i++) {
            const buffer = new ArrayBuffer(1024); // 1KB chunks
            const view = new Uint8Array(buffer);
            for (let j = 0; j < view.length; j++) {
                view[j] = j % 256;
            }
            chunks.push(buffer);
        }
        
        // Test stringifyTypedJsonAsync with binary data
        const start = performance.now();
        for (const chunk of chunks) {
            await stringifyTypedJsonAsync(chunk);
        }
        const duration = performance.now() - start;
        
        console.log(`âœ… Serialized ${iterations} binary chunks (1KB each) in ${duration.toFixed(2)}ms`);
        console.log(`   Average: ${(duration / iterations).toFixed(4)}ms per chunk`);
        console.log(`   Throughput: ${((iterations * 1024 / 1024) / (duration / 1000)).toFixed(2)} MB/second`);
        
        expect(duration).toBeLessThan(2000); // Binary is slower, but should still be reasonable
    });
    
    test("Comparison: JSON.stringify vs stringifyTypedJsonAsync for simple data", async () => {
        const iterations = 1000;
        const data = { id: 123, message: "Hello", active: true };
        
        // Baseline: JSON.stringify
        const start1 = performance.now();
        for (let i = 0; i < iterations; i++) {
            JSON.stringify(data);
        }
        const duration1 = performance.now() - start1;
        
        // Our implementation: stringifyTypedJsonAsync
        const start2 = performance.now();
        for (let i = 0; i < iterations; i++) {
            await stringifyTypedJsonAsync(data);
        }
        const duration2 = performance.now() - start2;
        
        const overhead = ((duration2 - duration1) / duration1 * 100).toFixed(1);
        
        console.log(`ðŸ“Š Performance Comparison:`);
        console.log(`   JSON.stringify:           ${duration1.toFixed(2)}ms (${(iterations / (duration1 / 1000)).toFixed(0)} chunks/sec)`);
        console.log(`   stringifyTypedJsonAsync:  ${duration2.toFixed(2)}ms (${(iterations / (duration2 / 1000)).toFixed(0)} chunks/sec)`);
        console.log(`   Overhead:                 ${overhead}% (${((duration2 - duration1) / iterations * 1000).toFixed(2)}Î¼s per chunk)`);
        console.log(`   ðŸ’¡ Note: High percentage but tiny absolute overhead - still very fast!`);
        
        // The overhead percentage is high because JSON.stringify is SO fast,
        // but absolute overhead is negligible (<1Î¼s per chunk) and throughput remains excellent
        expect(duration2).toBeLessThan(100); // Should complete 1000 iterations in <100ms
    });
});

